{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424f6026",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import segmentation_models_pytorch as smp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272b3c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_ROOT = Path(\"dataset/final_dataset\")\n",
    "AUG_DATASET_ROOT = Path(\"dataset/temp_aug_training\") \n",
    "PATH_BASELINE_EXP = Path(\"experiments/baseline_run/mit_FPN_20251227_xxxxx\") \n",
    "PATH_AUG_EXP      = Path(\"experiments/augmentation_run/mit_FPN_AUG_PHYSICAL_20251227_xxxxx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de30c96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "print(f\"Device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab153d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_files(root_dir, split):\n",
    "    return len(glob.glob(str(root_dir / split / \"images\" / \"*.png\")))\n",
    "\n",
    "n_train_base = count_files(DATASET_ROOT, \"train\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1939d7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if AUG_DATASET_ROOT.exists():\n",
    "    n_train_aug = count_files(AUG_DATASET_ROOT, \"train\")\n",
    "    # Cari file original di dalam folder aug (yang tidak ada _aug_)\n",
    "    all_aug_files = glob.glob(str(AUG_DATASET_ROOT / \"train\" / \"images\" / \"*.png\"))\n",
    "    n_train_base_actual = len([f for f in all_aug_files if \"_aug_\" not in f])\n",
    "    \n",
    "    data_counts = pd.DataFrame({\n",
    "        \"Dataset\": [\"Baseline (Original)\", \"Augmented (Physical)\"],\n",
    "        \"Total Images\": [n_train_base_actual, n_train_aug]\n",
    "    })\n",
    "    \n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.barplot(data=data_counts, x=\"Dataset\", y=\"Total Images\", palette=\"viridis\")\n",
    "    plt.title(\"Perbandingan Jumlah Data Training\")\n",
    "    plt.ylabel(\"Jumlah Gambar\")\n",
    "    for i, v in enumerate(data_counts[\"Total Images\"]):\n",
    "        plt.text(i, v + 5, str(v), ha='center', fontweight='bold')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Folder Augmented Temp tidak ditemukan. Pastikan path benar.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd69a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_overlay(img, mask, title=\"\"):\n",
    "    # img: HxW, mask: HxW\n",
    "    overlay = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
    "    # Mask merah transparan\n",
    "    overlay[(mask > 127)] = overlay[(mask > 127)] * 0.5 + np.array([255, 0, 0]) * 0.5\n",
    "    return overlay\n",
    "\n",
    "if AUG_DATASET_ROOT.exists():\n",
    "    train_dir = AUG_DATASET_ROOT / \"train\" / \"images\"\n",
    "    # Cari sampel yang punya versi aug\n",
    "    all_files = os.listdir(train_dir)\n",
    "    aug_files = [f for f in all_files if \"_aug_\" in f]\n",
    "    \n",
    "    if aug_files:\n",
    "        # Ambil 1 sampel acak\n",
    "        sample_aug_name = random.choice(aug_files)\n",
    "        # Rekonstruksi nama file asli\n",
    "        base_name = sample_aug_name.split(\"_aug_\")[0] + \".png\"\n",
    "        \n",
    "        # Load paths\n",
    "        path_orig_img = train_dir / base_name\n",
    "        path_orig_msk = AUG_DATASET_ROOT / \"train\" / \"masks\" / base_name\n",
    "        path_aug_img  = train_dir / sample_aug_name\n",
    "        path_aug_msk  = AUG_DATASET_ROOT / \"train\" / \"masks\" / sample_aug_name\n",
    "        \n",
    "        # Read Images\n",
    "        img_o = cv2.imread(str(path_orig_img), cv2.IMREAD_GRAYSCALE)\n",
    "        msk_o = cv2.imread(str(path_orig_msk), cv2.IMREAD_GRAYSCALE)\n",
    "        img_a = cv2.imread(str(path_aug_img), cv2.IMREAD_GRAYSCALE)\n",
    "        msk_a = cv2.imread(str(path_aug_msk), cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        # Plotting\n",
    "        plt.figure(figsize=(15, 8))\n",
    "        \n",
    "        # Baris 1: Original\n",
    "        plt.subplot(2, 3, 1); plt.imshow(img_o, cmap='gray'); plt.title(\"Original Image (Raw)\")\n",
    "        plt.subplot(2, 3, 2); plt.imshow(msk_o, cmap='gray'); plt.title(\"Original Mask\")\n",
    "        plt.subplot(2, 3, 3); plt.imshow(visualize_overlay(img_o, msk_o)); plt.title(\"Original Overlay\")\n",
    "        \n",
    "        # Baris 2: Augmented\n",
    "        plt.subplot(2, 3, 4); plt.imshow(img_a, cmap='gray'); plt.title(\"Augmented Image (Rotated/Shifted)\")\n",
    "        plt.subplot(2, 3, 5); plt.imshow(msk_a, cmap='gray'); plt.title(\"Augmented Mask\")\n",
    "        plt.subplot(2, 3, 6); plt.imshow(visualize_overlay(img_a, msk_a)); plt.title(\"Augmented Overlay\")\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"Tidak ada file augmented ditemukan.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58997ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_history(path):\n",
    "    csv = path / \"history.csv\"\n",
    "    if csv.exists(): return pd.read_csv(csv)\n",
    "    return None\n",
    "\n",
    "df_base = read_history(PATH_BASELINE_EXP)\n",
    "df_aug  = read_history(PATH_AUG_EXP)\n",
    "\n",
    "if df_base is not None and df_aug is not None:\n",
    "    epochs = range(1, len(df_base) + 1)\n",
    "    \n",
    "    plt.figure(figsize=(18, 5))\n",
    "    \n",
    "    # 1. Validation Dice\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.plot(df_base['val_dice'], label='Baseline', linestyle='--', color='blue')\n",
    "    plt.plot(df_aug['val_dice'],  label='Augmented', color='red', linewidth=2)\n",
    "    plt.title(\"Validation Dice Score (Higher is Better)\")\n",
    "    plt.xlabel(\"Epoch\"); plt.legend(); plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. Validation Loss\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.plot(df_base['val_loss'], label='Baseline', linestyle='--', color='blue')\n",
    "    plt.plot(df_aug['val_loss'],  label='Augmented', color='red', linewidth=2)\n",
    "    plt.title(\"Validation Loss (Lower is Better)\")\n",
    "    plt.xlabel(\"Epoch\"); plt.legend(); plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. Gap Analysis (Train Dice - Val Dice) -> Semakin kecil gap, semakin tidak overfitting\n",
    "    plt.subplot(1, 3, 3)\n",
    "    gap_base = df_base['train_dice'] - df_base['val_dice']\n",
    "    gap_aug  = df_aug['train_dice'] - df_aug['val_dice']\n",
    "    plt.plot(gap_base, label='Baseline Gap', linestyle='--', color='blue')\n",
    "    plt.plot(gap_aug,  label='Augmented Gap', color='red')\n",
    "    plt.axhline(0, color='black', linewidth=0.5)\n",
    "    plt.title(\"Overfitting Gap (Train - Val Dice)\")\n",
    "    plt.xlabel(\"Epoch\"); plt.legend(); plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74bf328",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load Models ---\n",
    "class GrayToRGB(torch.nn.Module):\n",
    "    def forward(self, x): return x.repeat(1, 3, 1, 1)\n",
    "\n",
    "def load_inference_model(path):\n",
    "    # Definisi ulang struktur model agar bisa load weights\n",
    "    model = smp.FPN(encoder_name=\"mit_b5\", encoder_weights=None, in_channels=3, classes=1)\n",
    "    full_model = torch.nn.Sequential(GrayToRGB(), model)\n",
    "    \n",
    "    if path.exists():\n",
    "        state = torch.load(path, map_location=DEVICE)\n",
    "        full_model.load_state_dict(state)\n",
    "        full_model.to(DEVICE)\n",
    "        full_model.eval()\n",
    "        return full_model\n",
    "    else:\n",
    "        print(f\"Model not found at: {path}\")\n",
    "        return None\n",
    "\n",
    "model_base = load_inference_model(PATH_BASELINE_EXP / \"weights/best_model.pt\")\n",
    "model_aug  = load_inference_model(PATH_AUG_EXP / \"weights/best_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0eb974",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img_dir = DATASET_ROOT / \"images\" # Sesuaikan path jika pakai folder test terpisah\n",
    "test_images = sorted(glob.glob(str(test_img_dir / \"*.png\")))\n",
    "\n",
    "# Ambil 3 sampel acak\n",
    "random.seed(42)\n",
    "sample_indices = random.sample(range(len(test_images)), 3)\n",
    "\n",
    "def predict_mask(model, img_tensor):\n",
    "    with torch.no_grad():\n",
    "        logits = model(img_tensor)\n",
    "        pred = (torch.sigmoid(logits) > 0.5).float()\n",
    "    return pred.cpu().numpy()[0, 0]\n",
    "\n",
    "if model_base and model_aug:\n",
    "    plt.figure(figsize=(15, 12))\n",
    "    \n",
    "    for i, idx in enumerate(sample_indices):\n",
    "        path = test_images[idx]\n",
    "        name = Path(path).stem\n",
    "        \n",
    "        # Read & Preprocess\n",
    "        img_raw = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "        h, w = img_raw.shape\n",
    "        \n",
    "        # Resize ke 512 untuk prediksi\n",
    "        img_in = cv2.resize(img_raw, (512, 512))\n",
    "        img_t = torch.from_numpy(img_in).float()/255.0\n",
    "        img_t = img_t.unsqueeze(0).unsqueeze(0).to(DEVICE)\n",
    "        \n",
    "        # Ground Truth\n",
    "        mask_path = DATASET_ROOT / \"masks\" / f\"{name}_mask.png\"\n",
    "        gt_raw = cv2.imread(str(mask_path), cv2.IMREAD_GRAYSCALE)\n",
    "        gt = cv2.resize(gt_raw, (512, 512))\n",
    "        \n",
    "        # Predict\n",
    "        p_base = predict_mask(model_base, img_t)\n",
    "        p_aug  = predict_mask(model_aug, img_t)\n",
    "        \n",
    "        # Difference Map (Green=Aug Better/Extra, Red=Base Better/Extra)\n",
    "        # Logic: Hijau jika Aug=1 Base=0. Merah jika Base=1 Aug=0.\n",
    "        diff = np.zeros((512, 512, 3))\n",
    "        diff[(p_aug==1) & (p_base==0)] = [0, 1, 0] # Hijau\n",
    "        diff[(p_aug==0) & (p_base==1)] = [1, 0, 0] # Merah\n",
    "        diff[(p_aug==1) & (p_base==1)] = [1, 1, 1] # Putih (Sepakat)\n",
    "        \n",
    "        # Plotting Row\n",
    "        row = i\n",
    "        plt.subplot(3, 5, row*5 + 1); plt.imshow(img_in, cmap='gray'); plt.title(\"Input\"); plt.axis('off')\n",
    "        plt.subplot(3, 5, row*5 + 2); plt.imshow(gt, cmap='gray'); plt.title(\"Ground Truth\"); plt.axis('off')\n",
    "        plt.subplot(3, 5, row*5 + 3); plt.imshow(p_base, cmap='gray'); plt.title(\"Baseline Pred\"); plt.axis('off')\n",
    "        plt.subplot(3, 5, row*5 + 4); plt.imshow(p_aug, cmap='gray'); plt.title(\"Augmented Pred\"); plt.axis('off')\n",
    "        plt.subplot(3, 5, row*5 + 5); plt.imshow(diff); plt.title(\"Diff (G:Aug, R:Base)\"); plt.axis('off')\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274ec713",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_dataset(model, img_paths, mask_root):\n",
    "    dices = []\n",
    "    worst_cases = [] # Simpan (score, img_path)\n",
    "    \n",
    "    for path in tqdm(img_paths, desc=\"Evaluating\"):\n",
    "        name = Path(path).stem\n",
    "        mask_path = mask_root / f\"{name}_mask.png\"\n",
    "        \n",
    "        if not mask_path.exists(): continue\n",
    "            \n",
    "        # Load & Prep\n",
    "        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "        gt = cv2.imread(str(mask_path), cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        img = cv2.resize(img, (512, 512))\n",
    "        gt  = cv2.resize(gt, (512, 512))\n",
    "        gt_bin = (gt > 127).astype(float)\n",
    "        \n",
    "        img_t = torch.from_numpy(img).float()/255.0\n",
    "        img_t = img_t.unsqueeze(0).unsqueeze(0).to(DEVICE)\n",
    "        \n",
    "        # Predict\n",
    "        pred = predict_mask(model, img_t)\n",
    "        \n",
    "        # Dice Score\n",
    "        intersection = (pred * gt_bin).sum()\n",
    "        dice = (2. * intersection) / (pred.sum() + gt_bin.sum() + 1e-7)\n",
    "        \n",
    "        dices.append(dice)\n",
    "        worst_cases.append((dice, path))\n",
    "        \n",
    "    return dices, sorted(worst_cases, key=lambda x: x[0])\n",
    "\n",
    "print(\"Calculating Full Statistics...\")\n",
    "scores_base, worst_base = evaluate_dataset(model_base, test_images, DATASET_ROOT / \"masks\")\n",
    "scores_aug,  worst_aug  = evaluate_dataset(model_aug,  test_images, DATASET_ROOT / \"masks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc0250d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Boxplot\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.boxplot([scores_base, scores_aug], labels=['Baseline', 'Augmented'], patch_artist=True)\n",
    "plt.title(\"Distribusi Dice Score pada Test Set\")\n",
    "plt.ylabel(\"Dice Score\")\n",
    "plt.grid(True, axis='y')\n",
    "plt.show()\n",
    "\n",
    "# --- B. Tampilkan Worst Cases Model Augmented ---\n",
    "print(\"\\n--- WORST CASES (AUGMENTED MODEL) ---\")\n",
    "plt.figure(figsize=(12, 4))\n",
    "for i in range(3):\n",
    "    score, path = worst_aug[i]\n",
    "    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    name = Path(path).stem\n",
    "    \n",
    "    plt.subplot(1, 3, i+1)\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.title(f\"{name}\\nDice: {score:.4f}\")\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f770b71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import wilcoxon\n",
    "stat, p = wilcoxon(scores_base, scores_aug)\n",
    "print(f\"Wilcoxon p-value: {p}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
